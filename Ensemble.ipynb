{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Plant Seedlings Classification](https://www.kaggle.com/competitions/plant-seedlings-classification/code)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from os import cpu_count, listdir, path\n",
    "from pathlib import Path\n",
    "from random import seed\n",
    "from typing import List, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "from torch import Tensor\n",
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global Variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch version: 2.5.1\n",
      "CPU cores: 8\n",
      "DEVICE: mps\n",
      "DATA_ROOT: data\n",
      "Random seed: 42\n",
      "Batch size: 64\n",
      "MPS available: True\n",
      "MPS built: True\n"
     ]
    }
   ],
   "source": [
    "# Metal Performance Shaders (MPS) - Apple Metal GPU acceleration\n",
    "def get_mps_device() -> torch.device:\n",
    "    if torch.backends.mps.is_available():\n",
    "        device = torch.device(\"mps\")\n",
    "        x = torch.ones(1, device=device)\n",
    "    elif torch.cuda.is_available():\n",
    "        device = torch.device(\"cuda\")\n",
    "        x = torch.ones(1, device=device)\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "    return device\n",
    "\n",
    "\n",
    "DEVICE = get_mps_device()\n",
    "\n",
    "DATA_ROOT = Path(\"./data\")\n",
    "TRAIN_DIR = DATA_ROOT / \"train\"\n",
    "TEST_DIR = DATA_ROOT / \"test\"\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "print(f\"Torch version: {torch.__version__}\")\n",
    "print(f\"CPU cores: {cpu_count()}\")\n",
    "\n",
    "print(f\"DEVICE: {DEVICE}\")\n",
    "print(f\"DATA_ROOT: {DATA_ROOT}\")\n",
    "print(\"Random seed:\", RANDOM_SEED)\n",
    "print(\"Batch size:\", BATCH_SIZE)\n",
    "\n",
    "print(\"MPS available:\", torch.backends.mps.is_available())\n",
    "print(\"MPS built:\", torch.backends.mps.is_built())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reproducibility\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "torch.cuda.manual_seed_all(RANDOM_SEED)\n",
    "\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: tensor([0.3288, 0.2894, 0.2073])\n",
      "Std: tensor([0.1039, 0.1093, 0.1266])\n"
     ]
    }
   ],
   "source": [
    "transform_resize = (224, 224)\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize(transform_resize),\n",
    "        transforms.ToTensor(),\n",
    "    ]\n",
    ")\n",
    "\n",
    "dataset = datasets.ImageFolder(root=TRAIN_DIR, transform=transform)\n",
    "loader = DataLoader(\n",
    "    dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4, pin_memory=True\n",
    ")\n",
    "\n",
    "total_sum = torch.zeros(3)\n",
    "total_squared_sum = torch.zeros(3)\n",
    "num_pixels = 0\n",
    "\n",
    "for images, _ in loader:\n",
    "    images: Tensor\n",
    "\n",
    "    total_sum += images.sum(dim=[0, 2, 3])\n",
    "    total_squared_sum += (images**2).sum(dim=[0, 2, 3])\n",
    "    num_pixels += images.size(0) * images.size(2) * images.size(3)\n",
    "\n",
    "transform_mean = total_sum / num_pixels\n",
    "transform_std = torch.sqrt((total_squared_sum / num_pixels) - (transform_mean**2))\n",
    "\n",
    "print(\"Mean:\", transform_mean)\n",
    "print(\"Std:\", transform_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CustomCNN(\n",
      "  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv4): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv5): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (relu): ReLU()\n",
      "  (fc1): Linear(in_features=12544, out_features=128, bias=True)\n",
      "  (fc2): Linear(in_features=128, out_features=12, bias=True)\n",
      "  (droupout): Dropout(p=0.5, inplace=False)\n",
      "  (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "KERNEL_SIZE = 3\n",
    "STRIDE = 1\n",
    "PADDING = 1\n",
    "\n",
    "\n",
    "class CustomCNN(torch.nn.Module):\n",
    "    def __init__(self, num_classes: int = len(dataset.classes)):\n",
    "        super(CustomCNN, self).__init__()\n",
    "\n",
    "        self.conv1 = torch.nn.Conv2d(\n",
    "            in_channels=3,\n",
    "            out_channels=16,\n",
    "            kernel_size=KERNEL_SIZE,\n",
    "            stride=STRIDE,\n",
    "            padding=PADDING,\n",
    "        )\n",
    "        self.conv2 = torch.nn.Conv2d(\n",
    "            in_channels=self.conv1.out_channels,\n",
    "            out_channels=32,\n",
    "            kernel_size=KERNEL_SIZE,\n",
    "            stride=STRIDE,\n",
    "            padding=PADDING,\n",
    "        )\n",
    "        self.conv3 = torch.nn.Conv2d(\n",
    "            in_channels=self.conv2.out_channels,\n",
    "            out_channels=64,\n",
    "            kernel_size=KERNEL_SIZE,\n",
    "            stride=STRIDE,\n",
    "            padding=PADDING,\n",
    "        )\n",
    "        self.conv4 = torch.nn.Conv2d(\n",
    "            in_channels=self.conv3.out_channels,\n",
    "            out_channels=128,\n",
    "            kernel_size=KERNEL_SIZE,\n",
    "            stride=STRIDE,\n",
    "            padding=PADDING,\n",
    "        )\n",
    "        self.conv5 = torch.nn.Conv2d(\n",
    "            in_channels=self.conv4.out_channels,\n",
    "            out_channels=256,\n",
    "            kernel_size=KERNEL_SIZE,\n",
    "            stride=STRIDE,\n",
    "            padding=PADDING,\n",
    "        )\n",
    "\n",
    "        self.pool = torch.nn.MaxPool2d(\n",
    "            kernel_size=2,\n",
    "            stride=2,\n",
    "            padding=0,\n",
    "        )\n",
    "\n",
    "        self.relu = torch.nn.ReLU()\n",
    "\n",
    "        dummy_input = torch.randn(1, 3, transform_resize[0], transform_resize[1])\n",
    "        with torch.no_grad():\n",
    "            in_features_fc1 = self.pool(\n",
    "                self.conv5(\n",
    "                    self.pool(\n",
    "                        self.conv4(\n",
    "                            self.pool(\n",
    "                                self.conv3(\n",
    "                                    self.pool(\n",
    "                                        self.conv2(self.pool(self.conv1(dummy_input)))\n",
    "                                    )\n",
    "                                )\n",
    "                            )\n",
    "                        )\n",
    "                    )\n",
    "                )\n",
    "            ).numel()\n",
    "\n",
    "        self.fc1 = torch.nn.Linear(\n",
    "            in_features=in_features_fc1,\n",
    "            out_features=128,\n",
    "        )\n",
    "        self.fc2 = torch.nn.Linear(\n",
    "            in_features=self.fc1.out_features,\n",
    "            out_features=num_classes,\n",
    "        )\n",
    "\n",
    "        self.droupout = torch.nn.Dropout(p=0.5)\n",
    "        self.bn1 = torch.nn.BatchNorm2d(self.conv1.out_channels)\n",
    "        self.bn2 = torch.nn.BatchNorm2d(self.conv2.out_channels)\n",
    "        self.bn3 = torch.nn.BatchNorm2d(self.conv3.out_channels)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        x = self.conv1(x)\n",
    "        # x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        # x = self.bn2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool(x)\n",
    "\n",
    "        x = self.conv3(x)\n",
    "        # x = self.bn3(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool(x)\n",
    "\n",
    "        x = self.conv4(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool(x)\n",
    "\n",
    "        x = self.conv5(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool(x)\n",
    "\n",
    "        # Flatten from (batch_size, C, H, W) to (batch_size, C*H*W)\n",
    "        x = x.view(x.size(0), -1)\n",
    "\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.droupout(x)\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "model = CustomCNN(num_classes=len(dataset.classes)).to(DEVICE)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load models\n",
    "model_custom_cnn: CustomCNN = torch.load(\n",
    "    DATA_ROOT / \"model_0.92695.pth\", map_location=DEVICE, weights_only=False\n",
    ")\n",
    "model_custom_cnn = model_custom_cnn.to(DEVICE)\n",
    "\n",
    "model_resnet: models.ResNet = torch.load(\n",
    "    DATA_ROOT / \"model_0.96095.pth\", map_location=DEVICE, weights_only=False\n",
    ")\n",
    "model_resnet = model_resnet.to(DEVICE)\n",
    "\n",
    "model_vit = torch.load(\n",
    "    DATA_ROOT / \"model_0.96725.pth\", map_location=DEVICE, weights_only=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test dataset length: 794\n"
     ]
    }
   ],
   "source": [
    "class TestDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.image_files = [f for f in listdir(root_dir) if f.endswith(\".png\")]\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx) -> Tuple[Tensor, str]:\n",
    "        img_path = path.join(self.root_dir, self.image_files[idx])\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, self.image_files[idx]\n",
    "\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize(transform_resize),\n",
    "        transforms.ToTensor(),\n",
    "    ]\n",
    ")\n",
    "\n",
    "test_dataset = TestDataset(root_dir=TEST_DIR, transform=transform)\n",
    "test_loader = DataLoader(\n",
    "    test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0, pin_memory=True\n",
    ")\n",
    "\n",
    "print(f\"Test dataset length: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom CNN weight: 0.3\n",
      "ResNet weight: 0.3\n",
      "ViT weight: 0.4\n",
      "Predictions saved to 'data/submission-2024-12-30_13-24-33.csv':\n",
      "            file           species\n",
      "0  1b490196c.png   Shepherds Purse\n",
      "1  85431c075.png  Loose Silky-bent\n",
      "2  506347cfe.png          Cleavers\n",
      "3  7f46a71db.png        Sugar beet\n",
      "4  668c1007c.png          Charlock\n"
     ]
    }
   ],
   "source": [
    "model_custom_cnn.eval()\n",
    "model_resnet.eval()\n",
    "model_vit.eval()\n",
    "\n",
    "w_custom_cnn = 0.25\n",
    "w_resnet = 0.25\n",
    "w_vit = 1 - w_custom_cnn - w_resnet\n",
    "\n",
    "print(f\"Custom CNN weight: {w_custom_cnn}\")\n",
    "print(f\"ResNet weight: {w_resnet}\")\n",
    "print(f\"ViT weight: {w_vit}\")\n",
    "\n",
    "predictions = []\n",
    "with torch.no_grad():\n",
    "    for images, image_names in test_loader:\n",
    "        images: Tensor\n",
    "        image_names: List[str]\n",
    "\n",
    "        images = images.to(DEVICE)\n",
    "        images_resnet = (\n",
    "            images.clone()\n",
    "            - torch.tensor([0.485, 0.456, 0.406]).to(DEVICE).view(1, 3, 1, 1)\n",
    "        ) / torch.tensor([0.229, 0.224, 0.225]).to(DEVICE).view(1, 3, 1, 1)\n",
    "        images_custom_cnn = (\n",
    "            images - transform_mean.to(DEVICE).view(1, 3, 1, 1)\n",
    "        ) / transform_std.to(DEVICE).view(1, 3, 1, 1)\n",
    "\n",
    "        probs_custom = torch.nn.functional.softmax(\n",
    "            model_custom_cnn(images_custom_cnn), dim=1\n",
    "        )\n",
    "        probs_resnet = torch.nn.functional.softmax(model_resnet(images_resnet), dim=1)\n",
    "        probs_vit = torch.nn.functional.softmax(model_vit(images_custom_cnn), dim=1)\n",
    "\n",
    "        ensemble_probs = (\n",
    "            w_custom_cnn * probs_custom + w_resnet * probs_resnet + w_vit * probs_vit\n",
    "        )\n",
    "\n",
    "        _, preds = torch.max(ensemble_probs, dim=1)\n",
    "\n",
    "        for image_name, pred in zip(image_names, preds):\n",
    "            predictions.append(\n",
    "                {\"file\": image_name, \"species\": dataset.classes[pred.item()]}\n",
    "            )\n",
    "\n",
    "submission_file = (\n",
    "    DATA_ROOT / f\"submission-{datetime.now().strftime('%Y-%m-%d_%H-%M-%S')}.csv\"\n",
    ")\n",
    "predictions_df = pd.DataFrame(predictions)\n",
    "predictions_df.to_csv(submission_file, index=False)\n",
    "\n",
    "print(f\"Predictions saved to '{submission_file}':\")\n",
    "print(predictions_df.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "uge",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
